{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7455fc-d079-405d-869d-de707455ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, BertTokenizerFast, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "train_data_path = 'spoken_train-v1.1.json'\n",
    "test_data_path = 'spoken_test-v1.1.json'\n",
    "fig_save_path = 'figs'\n",
    "MAX_LENGTH = 512\n",
    "MODEL_PATH = \"bert-base-uncased\"\n",
    "\n",
    "# Function to load data and preprocess it\n",
    "def load_data(path): \n",
    "    with open(path, 'rb') as f:\n",
    "        raw_data = json.load(f)\n",
    "    contexts, questions, answers = [], [], []\n",
    "\n",
    "    for group in raw_data['data']:\n",
    "        for paragraph in group['paragraphs']:\n",
    "            context = paragraph['context'].lower()\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question'].lower()\n",
    "                for answer in qa['answers']:\n",
    "                    answer['text'] = answer['text'].lower()\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "    return contexts, questions, answers\n",
    "\n",
    "train_contexts, train_questions, train_answers = load_data(train_data_path)\n",
    "valid_contexts, valid_questions, valid_answers = load_data(test_data_path)\n",
    "\n",
    "# Calculate end positions for answers\n",
    "def add_answer_end(answers, contexts):\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        answer['answer_end'] = answer['answer_start'] + len(answer['text'])\n",
    "\n",
    "add_answer_end(train_answers, train_contexts)\n",
    "add_answer_end(valid_answers, valid_contexts)\n",
    "\n",
    "# Tokenizer initialization\n",
    "tokenizerFast = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# Tokenization and Encoding\n",
    "def encode_data(questions, contexts, answers, tokenizer, max_length=MAX_LENGTH):\n",
    "    encodings = tokenizer(questions, contexts, max_length=max_length, truncation=True, padding=True)\n",
    "    start_positions, end_positions = [], []\n",
    "\n",
    "    for idx in range(len(answers)):\n",
    "        answer_encoding = tokenizer(answers[idx]['text'], truncation=True, padding=True)\n",
    "        ans_ids = answer_encoding['input_ids'][1:-1]  # exclude special tokens\n",
    "        for i in range(len(encodings['input_ids'][idx]) - len(ans_ids) + 1):\n",
    "            if encodings['input_ids'][idx][i:i+len(ans_ids)] == ans_ids:\n",
    "                start_positions.append(i)\n",
    "                end_positions.append(i + len(ans_ids) - 1)\n",
    "                break\n",
    "        else:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "    return encodings\n",
    "\n",
    "train_encodings = encode_data(train_questions, train_contexts, train_answers, tokenizerFast)\n",
    "valid_encodings = encode_data(valid_questions, valid_contexts, valid_answers, tokenizerFast)\n",
    "\n",
    "# Dataset class\n",
    "class SQuAD_Dataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, i):\n",
    "        return {k: torch.tensor(v[i]) for k, v in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "train_dataset = SQuAD_Dataset(train_encodings)\n",
    "valid_dataset = SQuAD_Dataset(valid_encodings)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=1)\n",
    "\n",
    "# Model class\n",
    "class QAModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QAModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(MODEL_PATH)\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(768 * 2, 2)\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
    "        hidden_states = torch.cat((outputs.hidden_states[-1], outputs.hidden_states[-3]), dim=-1)\n",
    "        logits = self.linear(self.drop_out(hidden_states))\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        return start_logits.squeeze(-1), end_logits.squeeze(-1)\n",
    "\n",
    "model = QAModel().to(device)\n",
    "\n",
    "# Focal loss function\n",
    "def focal_loss(start_logits, end_logits, start_positions, end_positions, gamma=1):\n",
    "    smax = nn.Softmax(dim=1)\n",
    "    log_probs_start = torch.log(smax(start_logits))\n",
    "    log_probs_end = torch.log(smax(end_logits))\n",
    "    nll = nn.NLLLoss()\n",
    "    fl_start = nll((1 - smax(start_logits)).pow(gamma) * log_probs_start, start_positions)\n",
    "    fl_end = nll((1 - smax(end_logits)).pow(gamma) * log_probs_end, end_positions)\n",
    "    return (fl_start + fl_end) / 2\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=2e-5, weight_decay=2e-2)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, dataloader):\n",
    "    model.train()\n",
    "    total_loss, total_acc = 0, 0\n",
    "    for batch in tqdm(dataloader, desc='Training'):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        \n",
    "        start_logits, end_logits = model(input_ids, attention_mask, token_type_ids)\n",
    "        loss = focal_loss(start_logits, end_logits, start_positions, end_positions)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_acc += ((torch.argmax(start_logits, dim=1) == start_positions).float().mean().item() +\n",
    "                      (torch.argmax(end_logits, dim=1) == end_positions).float().mean().item()) / 2\n",
    "    return total_loss / len(dataloader), total_acc / len(dataloader)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions, true_answers = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            start_true = batch['start_positions'].to(device)\n",
    "            end_true = batch['end_positions'].to(device)\n",
    "            \n",
    "            start_logits, end_logits = model(input_ids, attention_mask, token_type_ids)\n",
    "            start_pred = torch.argmax(start_logits, dim=1)\n",
    "            end_pred = torch.argmax(end_logits, dim=1)\n",
    "            \n",
    "            for i in range(len(start_pred)):\n",
    "                answer = tokenizerFast.decode(input_ids[i][start_pred[i]:end_pred[i]+1])\n",
    "                true_answer = tokenizerFast.decode(input_ids[i][start_true[i]:end_true[i]+1])\n",
    "                predictions.append(answer if answer else \"$\")\n",
    "                true_answers.append(true_answer if true_answer else \"$\")\n",
    "    \n",
    "    from evaluate import load\n",
    "    wer = load(\"wer\")\n",
    "    wer_score = wer.compute(predictions=predictions, references=true_answers)\n",
    "    return wer_score\n",
    "\n",
    "# Main training loop\n",
    "EPOCHS = 6\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_model(model, train_data_loader)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train Accuracy = {train_acc:.4f}\")\n",
    "    wer_score = evaluate_model(model, valid_data_loader)\n",
    "    print(f\"Epoch {epoch+1}: WER = {wer_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
